{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Merge, merge\n",
    "from keras.layers import Input, Activation, Dense, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from multi_gpu import make_parallel #Available here https://github.com/kuza55/keras-extras/blob/master/utils/multi_gpu.py\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import backend as K\n",
    "import os\n",
    "from sklearn.utils import shuffle\n",
    "import random\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from sklearn.metrics import fbeta_score\n",
    "from keras.optimizers import Adam, SGD\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0, 1, 2, 3\"\n",
    "\n",
    "def fbeta_loss(y_true, y_pred):\n",
    "    beta_squared = 4\n",
    "\n",
    "    tp = K.sum(y_true * y_pred) + K.epsilon()\n",
    "    fp = K.sum(y_pred) - tp\n",
    "    fn = K.sum(y_true) - tp\n",
    "\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "\n",
    "    result = 1 - (beta_squared + 1) * (precision * recall) / (beta_squared * precision + recall + K.epsilon())\n",
    "\n",
    "    return result\n",
    "\n",
    "def fbeta_score_K(y_true, y_pred):\n",
    "    beta_squared = 4\n",
    "\n",
    "    tp = K.sum(y_true * y_pred) + K.epsilon()\n",
    "    fp = K.sum(y_pred) - tp\n",
    "    fn = K.sum(y_true) - tp\n",
    "\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "\n",
    "    result = (beta_squared + 1) * (precision * recall) / (beta_squared * precision + recall + K.epsilon())\n",
    "\n",
    "    return result\n",
    "\n",
    "def rotate(img):\n",
    "    rows = img.shape[0]\n",
    "    cols = img.shape[1]\n",
    "    angle = np.random.choice((10, 20, 30))#, 40, 50, 60, 70, 80, 90))\n",
    "    rotation_M = cv2.getRotationMatrix2D((cols / 2, rows / 2), angle, 1)\n",
    "    img = cv2.warpAffine(img, rotation_M, (cols, rows))\n",
    "    return img\n",
    "\n",
    "def rotate_bound(image, size):\n",
    "    #credits http://www.pyimagesearch.com/2017/01/02/rotate-images-correctly-with-opencv-and-python/\n",
    "    (h, w) = image.shape[:2]\n",
    "    (cX, cY) = (w // 2, h // 2)\n",
    "\n",
    "    angle = np.random.randint(10,180)\n",
    "\n",
    "    M = cv2.getRotationMatrix2D((cX, cY), -angle, 1.0)\n",
    "    cos = np.abs(M[0, 0])\n",
    "    sin = np.abs(M[0, 1])\n",
    "\n",
    "    # compute the new bounding dimensions of the image\n",
    "    nW = int((h * sin) + (w * cos))\n",
    "    nH = int((h * cos) + (w * sin))\n",
    "\n",
    "    # adjust the rotation matrix to take into account translation\n",
    "    M[0, 2] += (nW / 2) - cX\n",
    "    M[1, 2] += (nH / 2) - cY\n",
    "\n",
    "    output = cv2.resize(cv2.warpAffine(image, M, (nW, nH)), (size, size))\n",
    "    return output\n",
    "\n",
    "def perspective(img):\n",
    "    rows = img.shape[0]\n",
    "    cols = img.shape[1]\n",
    "\n",
    "    shrink_ratio1 = np.random.randint(low=85, high=110, dtype=int) / 100\n",
    "    shrink_ratio2 = np.random.randint(low=85, high=110, dtype=int) / 100\n",
    "\n",
    "    zero_point = rows - np.round(rows * shrink_ratio1, 0)\n",
    "    max_point_row = np.round(rows * shrink_ratio1, 0)\n",
    "    max_point_col = np.round(cols * shrink_ratio2, 0)\n",
    "\n",
    "    src = np.float32([[zero_point, zero_point], [max_point_row-1, zero_point], [zero_point, max_point_col+1], [max_point_row-1, max_point_col+1]])\n",
    "    dst = np.float32([[0, 0], [rows, 0], [0, cols], [rows, cols]])\n",
    "\n",
    "    perspective_M = cv2.getPerspectiveTransform(src, dst)\n",
    "\n",
    "    img = cv2.warpPerspective(img, perspective_M, (cols,rows))#, borderValue=mean_pix)\n",
    "    return img\n",
    "\n",
    "def shift(img):\n",
    "    rows = img.shape[0]\n",
    "    cols = img.shape[1]\n",
    "\n",
    "    shift_ratio1 = (random.random() * 2 - 1) * np.random.randint(low=3, high=15, dtype=int)\n",
    "    shift_ratio2 = (random.random() * 2 - 1) * np.random.randint(low=3, high=15, dtype=int)\n",
    "\n",
    "    shift_M = np.float32([[1,0,shift_ratio1], [0,1,shift_ratio2]])\n",
    "    img = cv2.warpAffine(img, shift_M, (cols, rows))#, borderValue=mean_pix)\n",
    "    return img\n",
    "\n",
    "def batch_generator_train(zip_list, img_size, batch_size, is_train=True, shuffle=True):\n",
    "    number_of_batches = np.ceil(len(zip_list) / batch_size)\n",
    "    if shuffle == True:\n",
    "        random.shuffle(zip_list)\n",
    "    counter = 0\n",
    "    while True:\n",
    "        if shuffle == True:\n",
    "            random.shuffle(zip_list)\n",
    "\n",
    "        batch_files = zip_list[batch_size*counter:batch_size*(counter+1)]\n",
    "        image_list = []\n",
    "        mask_list = []\n",
    "\n",
    "        for file, mask in batch_files:\n",
    "\n",
    "            image = cv2.imread(file) #cv2.resize(cv2.imread(file), (img_size,img_size)) / 255.\n",
    "            image = cv2.resize(image, (224, 224)) \n",
    "            image = image[:, :, [2, 1, 0]] - mean_pix\n",
    "\n",
    "            rnd_flip = np.random.randint(2, dtype=int)\n",
    "            rnd_rotate = np.random.randint(2, dtype=int)\n",
    "            rnd_zoom = np.random.randint(2, dtype=int)\n",
    "            rnd_shift = np.random.randint(2, dtype=int)\n",
    "\n",
    "            if (rnd_flip == 1) & (is_train == True):\n",
    "                rnd_flip = np.random.randint(3, dtype=int) - 1\n",
    "                image = cv2.flip(image, rnd_flip)\n",
    "\n",
    "            if (rnd_rotate == 1) & (is_train == True):\n",
    "                image = rotate_bound(image, img_size)\n",
    "\n",
    "            if (rnd_zoom == 1) & (is_train == True):\n",
    "                image = perspective(image)\n",
    "\n",
    "            if (rnd_shift == 1) & (is_train == True):\n",
    "                image = shift(image)\n",
    "\n",
    "            image_list.append(image)\n",
    "            mask_list.append(mask)\n",
    "\n",
    "        counter += 1\n",
    "        image_list = np.array(image_list)\n",
    "        mask_list = np.array(mask_list)\n",
    "\n",
    "        yield (image_list, mask_list)\n",
    "\n",
    "        if counter == number_of_batches:\n",
    "            if shuffle == True:\n",
    "                random.shuffle(zip_list)\n",
    "            counter = 0\n",
    "\n",
    "def batch_generator_test(zip_list, img_size, batch_size, shuffle=True):\n",
    "    number_of_batches = np.ceil(len(zip_list)/batch_size)\n",
    "    print(len(zip_list), number_of_batches)\n",
    "    counter = 0\n",
    "    if shuffle:\n",
    "        random.shuffle(zip_list)\n",
    "    while True:\n",
    "        batch_files = zip_list[batch_size*counter:batch_size*(counter+1)]\n",
    "        image_list = []\n",
    "        mask_list = []\n",
    "\n",
    "        for file, mask in batch_files:\n",
    "\n",
    "            image = cv2.resize(cv2.imread(file), (img_size, img_size))\n",
    "            image = image[:, :, [2, 1, 0]] - mean_pix\n",
    "            image_list.append(image)\n",
    "            mask_list.append(mask)\n",
    "\n",
    "        counter += 1\n",
    "        image_list = np.array(image_list)\n",
    "        mask_list = np.array(mask_list)\n",
    "\n",
    "        yield (image_list, mask_list)\n",
    "\n",
    "        if counter == number_of_batches:\n",
    "            random.shuffle(zip_list)\n",
    "            counter = 0\n",
    "\n",
    "def predict_generator(files, img_size, batch_size):\n",
    "    number_of_batches = np.ceil(len(files) / batch_size)\n",
    "    print(len(files), number_of_batches)\n",
    "    counter = 0\n",
    "    int_counter = 0\n",
    "\n",
    "    while True:\n",
    "            beg = batch_size * counter\n",
    "            end = batch_size * (counter + 1)\n",
    "            batch_files = files[beg:end]\n",
    "            image_list = []\n",
    "\n",
    "            for file in batch_files:\n",
    "                int_counter += 1\n",
    "                image = cv2.resize(cv2.imread(file), (img_size, img_size))\n",
    "                image = image[:, :, [2, 1, 0]] - mean_pix\n",
    "\n",
    "                rnd_flip = np.random.randint(2, dtype=int)\n",
    "                rnd_rotate = np.random.randint(2, dtype=int)\n",
    "                rnd_zoom = np.random.randint(2, dtype=int)\n",
    "                rnd_shift = np.random.randint(2, dtype=int)\n",
    "\n",
    "                if rnd_flip == 1:\n",
    "                    rnd_flip = np.random.randint(3, dtype=int) - 1\n",
    "                    image = cv2.flip(image, rnd_flip)\n",
    "\n",
    "                if rnd_rotate == 1:\n",
    "                    image = rotate_bound(image, img_size)\n",
    "\n",
    "                if rnd_zoom == 1:\n",
    "                    image = perspective(image)\n",
    "\n",
    "                if rnd_shift == 1:\n",
    "                    image = shift(image)\n",
    "\n",
    "                image_list.append(image)\n",
    "\n",
    "            counter += 1\n",
    "\n",
    "            image_list = np.array(image_list)\n",
    "\n",
    "            yield (image_list)\n",
    "\n",
    "\n",
    "def f2_score(y_true, y_pred):\n",
    "    y_true, y_pred, = np.array(y_true), np.array(y_pred)\n",
    "    score = fbeta_score(y_true, y_pred, beta=2, average='samples')\n",
    "    return score\n",
    "\n",
    "GLOBAL_PATH = '/shared_datasets/kaggle/Amazon/'\n",
    "TRAIN_FOLDER = '/shared_datasets/kaggle/Amazon/data/train-jpg/' #All train files resized to 224*224\n",
    "TEST_FOLDER = '/shared_datasets/kaggle/Amazon/data/test-jpg/' #All test files in one folder\n",
    "TEST_FOLDER_ADD = '/shared_datasets/kaggle/Amazon/data/test-jpg-additional/' #All test files in one folder\n",
    "F_CLASSES = GLOBAL_PATH + 'data/train_v2.csv'\n",
    "\n",
    "df_train = pd.read_csv(F_CLASSES)\n",
    "df_test = pd.read_csv(GLOBAL_PATH + 'data/sample_submission_v2.csv')\n",
    "\n",
    "labels = ['blow_down',\n",
    "          'bare_ground',\n",
    "          'conventional_mine',\n",
    "          'blooming',\n",
    "          'cultivation',\n",
    "          'artisinal_mine',\n",
    "          'haze',\n",
    "          'primary',\n",
    "          'slash_burn',\n",
    "          'habitation',\n",
    "          'clear',\n",
    "          'road',\n",
    "          'selective_logging',\n",
    "          'partly_cloudy',\n",
    "          'agriculture',\n",
    "          'water',\n",
    "          'cloudy']\n",
    "label_map = {'agriculture': 14,\n",
    "             'artisinal_mine': 5,\n",
    "             'bare_ground': 1,\n",
    "             'blooming': 3,\n",
    "             'blow_down': 0,\n",
    "             'clear': 10,\n",
    "             'cloudy': 16,\n",
    "             'conventional_mine': 2,\n",
    "             'cultivation': 4,\n",
    "             'habitation': 9,\n",
    "             'haze': 6,\n",
    "             'partly_cloudy': 13,\n",
    "             'primary': 7,\n",
    "             'road': 11,\n",
    "             'selective_logging': 12,\n",
    "             'slash_burn': 8,\n",
    "             'water': 15}\n",
    "\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "\n",
    "x_train = []\n",
    "x_test = []\n",
    "y_train = []\n",
    "\n",
    "\n",
    "for f, tags in tqdm(df_train.values, miniters=1000):\n",
    "    img = TRAIN_FOLDER + '{}.jpg'.format(f)\n",
    "    targets = np.zeros(17)\n",
    "    for t in tags.split(' '):\n",
    "        targets[label_map[t]] = 1\n",
    "    x_train.append(img)\n",
    "    y_train.append(targets)\n",
    "\n",
    "\n",
    "x_train, x_holdout, y_train, y_holdout = x_train[3000:-1], x_train[:3000], y_train[3000:-1], y_train[:3000]\n",
    "\n",
    "x_train, y_train = shuffle(x_train, y_train, random_state = 24)\n",
    "\n",
    "part = 0.85\n",
    "split = int(round(part*len(y_train)))\n",
    "x_train, x_valid, y_train, y_valid = x_train[:split], x_train[split:], y_train[:split], y_train[split:]\n",
    "print('x tr: ', len(x_train))\n",
    "\n",
    "#define callbacks\n",
    "callbacks = [ModelCheckpoint('amazon_2007.hdf5', monitor='val_loss', save_best_only=True, verbose=2, save_weights_only=False),\n",
    "             ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, verbose=1, mode='auto', epsilon=0.0001, cooldown=0, min_lr=0.0000001),\n",
    "             EarlyStopping(monitor='val_loss', patience=5, verbose=0)]\n",
    "\n",
    "BATCH = 512\n",
    "IMG_SIZE = 224\n",
    "mean_pix = np.array([102.9801, 115.9465, 122.7717]) #It is BGR\n",
    "\n",
    "from keras.applications import ResNet50\n",
    "\n",
    "#Compile model and set non-top layets non-trainable (warm-up)\n",
    "base_model = ResNet50(include_top=False, input_shape=(IMG_SIZE,IMG_SIZE,3), pooling='avg', weights='imagenet')\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = base_model.output\n",
    "x = Dense(2048, activation='relu')(x)\n",
    "x = Dropout(0.25)(x)\n",
    "output = Dense(17, activation='sigmoid')(x)\n",
    "\n",
    "optimizer = Adam(0.001, decay=0.0003)\n",
    "model = Model(inputs=base_model.inputs, outputs=output)\n",
    "model = make_parallel(model, 2)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy', fbeta_score_K])\n",
    "\n",
    "model.fit_generator(generator=batch_generator_train(list(zip(x_train, y_train)), IMG_SIZE, BATCH),\n",
    "                          steps_per_epoch=np.ceil(len(x_train)/BATCH),\n",
    "                          epochs=1,\n",
    "                          verbose=1,\n",
    "                          validation_data=batch_generator_train(list(zip(x_valid, y_valid)), IMG_SIZE, 16),\n",
    "                          validation_steps=np.ceil(len(x_valid)/16),\n",
    "                          callbacks=callbacks,\n",
    "                          initial_epoch=0)\n",
    "\n",
    "\n",
    "#Compile model and set all layers trainable\n",
    "optimizer = Adam(0.0001, decay=0.00000001)\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy', fbeta_score_K])\n",
    "model.load_weights('amazon_2007.hdf5', by_name=True)\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "BATCH = 128\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy', fbeta_score_K])\n",
    "model.fit_generator(generator=batch_generator_train(list(zip(x_train, y_train)), IMG_SIZE, BATCH),\n",
    "                          steps_per_epoch=np.ceil(len(x_train)/BATCH),\n",
    "                          epochs=50,\n",
    "                          verbose=1,\n",
    "                          validation_data=batch_generator_train(list(zip(x_valid, y_valid)), IMG_SIZE, 16),\n",
    "                          validation_steps=np.ceil(len(x_valid)/16),\n",
    "                          callbacks=callbacks,\n",
    "                          initial_epoch=0)\n",
    "\n",
    "model.load_weights('amazon_2007.hdf5')\n",
    "\n",
    "\n",
    "x_val = []\n",
    "y_val = []\n",
    "x_hld = []\n",
    "y_hld = []\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "\n",
    "#====================== validation set est =================================\n",
    "for f, tags in tqdm(list(zip(x_valid, y_valid)), miniters=1000):\n",
    "    y_val.append(tags)\n",
    "\n",
    "p_valid = model.predict_generator(batch_generator_test(list(zip(x_valid, y_valid)), IMG_SIZE, 8, shuffle=False), steps=np.ceil(len(x_valid)/8))\n",
    "\n",
    "print('val_set: ', fbeta_score(np.array(y_val), np.array(p_valid) > 0.2, beta=2, average='samples'))\n",
    "#===========================================================================\n",
    "\n",
    "def optimise_f2_thresholds(y, p, verbose=True, resolution=100):\n",
    "    #credits https://www.kaggle.com/c/planet-understanding-the-amazon-from-space/discussion/32475\n",
    "    def mf(x):\n",
    "        p2 = np.zeros_like(p)\n",
    "        for i in range(17):\n",
    "            p2[:, i] = (p[:, i] > x[i]).astype(np.int)\n",
    "        score = fbeta_score(y, p2, beta=2, average='samples')\n",
    "        return score\n",
    "\n",
    "    x = [0.2]*17\n",
    "    for i in range(17):\n",
    "        best_i2 = 0\n",
    "        best_score = 0\n",
    "        for i2 in range(resolution):\n",
    "            i2 /= resolution\n",
    "            x[i] = i2\n",
    "            score = mf(x)\n",
    "            if score > best_score:\n",
    "                best_i2 = i2\n",
    "                best_score = score\n",
    "        x[i] = best_i2\n",
    "        if verbose:\n",
    "            print(i, best_i2, best_score)\n",
    "\n",
    "    return x\n",
    "\n",
    "X = optimise_f2_thresholds(np.array(y_val), np.array(p_valid))\n",
    "\n",
    "#====================== holdout set est =================================\n",
    "for f, tags in tqdm(list(zip(x_holdout, y_holdout)), miniters=1000):\n",
    "    img = cv2.resize(cv2.imread(f), (IMG_SIZE, IMG_SIZE))\n",
    "    x_hld.append(img)\n",
    "    y_hld.append(tags)\n",
    "\n",
    "if len(x_holdout) % 2 > 0:\n",
    "    x_hld.append(x_hld[0])\n",
    "    y_hld.append(y_hld[0])\n",
    "\n",
    "x_hld = np.array(x_hld, np.float16)\n",
    "\n",
    "p_valid = model.predict(x_hld, batch_size=28, verbose=2)\n",
    "print('holdout set: ', f2_score(np.array(y_hld), np.array(p_valid) > 0.2))\n",
    "print('holdout set w/ thresh: ', f2_score(np.array(y_hld), np.array(p_valid) > 0.19))\n",
    "#===========================================================================\n",
    "\n",
    "\n",
    "for f, tags in tqdm(df_test.values, miniters=1000):\n",
    "    if 'test' in f:\n",
    "        img = TEST_FOLDER + '{}.jpg'.format(f)\n",
    "    else:\n",
    "        img = TEST_FOLDER_ADD + '{}.jpg'.format(f)\n",
    "    x_test.append(img)\n",
    "\n",
    "batch_size_test = 32\n",
    "len_test = len(x_test)\n",
    "x_tst = []\n",
    "yfull_test = []\n",
    "\n",
    "\n",
    "TTA_steps = 30\n",
    "\n",
    "for k in range(0, TTA_steps):\n",
    "    print(k)\n",
    "    probs = model.predict_generator(predict_generator(x_test,IMG_SIZE,batch_size_test), steps=np.ceil(len(x_test)/batch_size_test),verbose=1)\n",
    "    yfull_test.append(probs)\n",
    "    k += 1\n",
    "\n",
    "result = np.array(yfull_test[0])\n",
    "\n",
    "for i in range(1, TTA_steps):\n",
    "    result += np.array(yfull_test[i])\n",
    "result /= TTA_steps\n",
    "\n",
    "res = pd.DataFrame(result, columns=labels)\n",
    "preds = []\n",
    "\n",
    "for i in tqdm(range(res.shape[0]), miniters=1000):\n",
    "    a = res.ix[[i]]\n",
    "    a = a.apply(lambda x: x > X, axis=1)\n",
    "    a = a.transpose()\n",
    "    a = a.loc[a[i] == True]\n",
    "    ' '.join(list(a.index))\n",
    "    preds.append(' '.join(list(a.index)))\n",
    "\n",
    "print(len(preds))\n",
    "\n",
    "df_test['tags'] = preds\n",
    "df_test = df_test[:-57]\n",
    "df_test.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
